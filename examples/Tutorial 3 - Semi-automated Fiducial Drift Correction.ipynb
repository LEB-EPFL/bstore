{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The need to interactively tune the fiducial marker detection and check its output means that drift correction should not be performed in batch. However, the drift correction process can be made simpler by using a notebook that assists in finding the files and performing the drift correction. This notebook serves as the template for this step.\n",
    "\n",
    "Note: Typically, this step would be performed before the actual batch processing in tutorial 2. Since tutorial 2 was easier, though, I thought it would be best to explain it before this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the software libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import DataSTORM.processors as proc\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of steps\n",
    "1. Search the parent directory for all localization files and a build a list of such files\n",
    "2. Define the drift correction processor\n",
    "3. Open a file from the list\n",
    "4. Perform the drift correction on the file\n",
    "  * If the correction was not good, go back to step 2\n",
    "4. Save the results\n",
    "5. Repeat from step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the parent directory and make a list of localization files\n",
    "We will start by searching a parent directory and its subdirectories for all the localization files, i.e. those files that end in `locResults.dat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "parentDirectory   = Path('../test-data/Centrioles/')\n",
    "localizationFiles = parentDirectory.glob('**/*locResults.dat')\n",
    "locResultFiles    = sorted(localizationFiles)\n",
    "\n",
    "# How many files are there?\n",
    "print(len(locResultFiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`locResultFiles` is an array of files ending in `locResults.dat` within the parent directory `../test-data/Centrioles/` and its subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../test-data/Centrioles/FOV_1_noPB_1500mW_10ms_1/FOV_1_noPB_1500mW_10ms_1_MMStack_locResults.dat')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locResultFiles[0] # In Python, array indexes start at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../test-data/Centrioles/FOV_7_noPB_1500mW_10ms_1/FOV_7_noPB_1500mW_10ms_1_MMStack_locResults.dat')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locResultFiles[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the drift correction processor\n",
    "This part is the same as in Tutorial 1. At the end of processing for each file, return to this code block and start running the blocks again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the FiducialDriftCorrect processor and set its properties.\n",
    "dc = proc.FiducialDriftCorrect(minFracFiducialLength = 0.5,\n",
    "                               neighborRadius        = 500,\n",
    "                               smoothingWindowSize   = 2000,\n",
    "                               smoothingFilterSize   = 500,\n",
    "                               interactiveSearch     = True,\n",
    "                               noLinking             = True)\n",
    "\n",
    "clean = proc.CleanUp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open a file from the list\n",
    "Now, we're going to open the first file in this list, locResultFiles[0]. When we are all done with this file, we will come back to here and increase the index by one (to locResultFiles[1], and so on...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the input and output files\n",
    "currentFile = locResultFiles[0] # Increment this when done dedrifting a dataset\n",
    "outputFile  = currentFile.parent / Path(currentFile.stem + '_DC' + currentFile.suffix)\n",
    "\n",
    "# Open a file and clean it up\n",
    "with open(str(currentFile), 'r') as file:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "df = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
