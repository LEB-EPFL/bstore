{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe that out-of-core merging will be easier if I use HDF streams to do the data processing. This notebook is an attempt to understand the file type and how it works in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab\n",
    "import DataSTORM.processors as proc\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an HDF5 file\n",
    "I don't currently have an HDF5 file, so I will create one from existing test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileIn = Path('../test-data/Centrioles/FOV_7_noPB_1500mW_10ms_1/FOV_7_noPB_1500mW_10ms_1_MMStack_locResults_DC.dat')\n",
    "with open(str(fileIn), 'r') as file:\n",
    "    df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save a DataFrame as an hdf5 file, we use the to_hdf() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileOut = fileIn.parent / Path(fileIn.stem + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_hdf(str(fileOut),\n",
    "          key    = 'localizations',\n",
    "          format = 'table',\n",
    "          mode   = 'w',\n",
    "          data_columns = ['loglikelihood'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether to_hdf() succeeds depends critically on the arguments passed to it. Here's a brief description of the above parameters:\n",
    "\n",
    "1. **key = 'localizations'** This is the identifier for the table inside the hdf5 store\n",
    "2. **format = 'table'** This allows for searching the data from inside the store. The alternative and default argument is **'fixed'**, which is faster but not searchable.\n",
    "3. **mode = 'w'** to_hdf() threw some strange errors until I added this part.\n",
    "4. **data_columns** = ['loglikelihood'] sets only this column to be searchable. That is, we can query this column only using select operations. Note that column headers with units and spaces are not selectable currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading hdf5 files\n",
    "Let's start by simplying obtaining the keys that identify the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore(str(fileOut), mode = 'r')\n",
    "for key in hdf.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to close the hdf store when we are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see if I can read in specific columns from the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore(str(fileOut), mode = 'r')\n",
    "df2 = hdf.select(key   = 'localizations',\n",
    "                 where = [pd.Term('columns', '=', ['x [nm]', 'y [nm]'])])\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also attempt to read in files using read_hdf()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_hdf(str(fileOut),\n",
    "                  key = 'localizations',\n",
    "                  columns = ['x [nm]', 'y [nm]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can also read from a store and filter the inputs at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore(str(fileOut), mode = 'r')\n",
    "df4 = hdf.select(key     = 'localizations',\n",
    "                 columns = ['x [nm]', 'y [nm]', 'loglikelihood'],\n",
    "                 where   = [pd.Term('loglikelihood', '<', 250.0)])\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df4.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = pd.HDFStore(str(fileOut), mode = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import trackpy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tp.PandasHDFStoreBig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
