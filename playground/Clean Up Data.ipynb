{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleanup\n",
    "\n",
    "Sometimes MATLAB writes individual entries into the localization files that are not easily parsed (or impossible to parse in ThunderSTORM). For this reason, I need to find a way to clean up the data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab\n",
    "import DataSTORM.processors as ds\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = Path('../test-data/MicroTubules_LargeFOV/FOV1_1500_10ms_1_MMStack_locResults.dat')\n",
    "with open(str(filename.resolve()), 'r') as file:\n",
    "    df = pd.read_csv(file, engine = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the data in the uncertainty column was saved such that most of the numbers are floats, but some are strings representing floats and some are in a strange complex exponential form. Let's filter out these rows to make working with the data frame easier and to protoype a clean up routine.\n",
    "\n",
    "First, I'll generate a mask to pick out the rows containing strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stringMask = df['uncertainty [nm]'].map(lambda x: isinstance(x, str)).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what the strings look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['uncertainty [nm]'][stringMask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, strangely there were about 11,000 localizations that were interpreted as strings in this data set. Let's cast them as numeric data types. Some of the strings cannot be recognized by the parser, so we'll convert those to NaN's by using the `errors='coerce'` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['uncertainty [nm]'] = pd.to_numeric(df['uncertainty [nm]'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to replace any Inf's with NaN's and then drop the NaN's. We'll reindex the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "df.dropna().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.reindex()\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal localization processing\n",
    "Now that the data is cleaned up a bit, we'll proceed with our normal processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FilterLLR  = ds.Filter('loglikelihood', '<', 400)\n",
    "FilterSig1 = ds.Filter('sigma [nm]',    '>', 100)\n",
    "FilterSig2 = ds.Filter('sigma [nm]',    '<', 180)\n",
    "df2        = FilterSig2(FilterSig1(FilterLLR(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the 2D histogram to visually identify fiducials\n",
    "\n",
    "Now we need to make a 2D histogram to see whether the fiducial localizations are apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find maximum x or y coordinate\n",
    "maxPos    = np.max([df2['x [nm]'].max(), df2['y [nm]'].max()])\n",
    "pixelSize = 100 # nm\n",
    "\n",
    "numBins = int(maxPos / pixelSize)\n",
    "plt.hist2d(df2['x [nm]'], df2['y [nm]'], bins = numBins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corrector = ds.FiducialDriftCorrect(mergeRadius           = 50,\n",
    "                                    offTime               = 1,\n",
    "                                    minSegmentLength      = 20,\n",
    "                                    minFracFiducialLength = 0.4,\n",
    "                                    neighborRadius        = 500,\n",
    "                                    smoothingWindowSize   = 625,\n",
    "                                    smoothingFilterSize   = 500,\n",
    "                                    searchRegions         = [{'xMin' :  2200,\n",
    "                                                              'xMax' :  2800,\n",
    "                                                              'yMin' : 33200,\n",
    "                                                              'yMax' : 33700}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = corrector(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find maximum x or y coordinate\n",
    "maxPos    = np.max([df3['x [nm]'].max(), df3['y [nm]'].max()])\n",
    "pixelSize = 100 # nm\n",
    "\n",
    "numBins = int(maxPos / pixelSize)\n",
    "plt.hist2d(df3['x [nm]'], df3['y [nm]'], bins = numBins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x0 = corrector.fiducialTrajectories[0]['x'].iloc[[0]].as_matrix()\n",
    "plt.plot(corrector.fiducialTrajectories[0]['frame'], corrector.fiducialTrajectories[0]['x'] - x0)\n",
    "plt.plot(corrector.avgSpline.index,corrector.avgSpline['xS'])\n",
    "plt.plot(np.arange(100,50000), corrector.splines['xS'][0](np.arange(100,50000)) - x0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BE SURE TO DROP NULLS FIRST\n",
    "df3.dropna(inplace = True)\n",
    "df3.to_csv('fullData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5 = df2[df2['frame'] > 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df5.to_csv('partialData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
