{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing custom readers\n",
    "\n",
    "Readers were introduced in version 1.1.0 to better enable B-Store to read data from various filetypes. A Reader is used to read the data contained in a particular file into a Python datatype, such as Pandas DataFrame or Numpy array. This intermediate Python datatype is a sort of temporary holding spot before the data is then placed into a HDF file. The abstract base class `Reader` defines a common interface for users to write their own routines for reading any type of file into Python.\n",
    "\n",
    "To use a `Reader` when creating a `HDFDatastore`, one passes one or more instances of objects that subclass `Reader` and that to `HDFDatastore.build()` or `Parser.parseFilename()`. This will be described below.\n",
    "\n",
    "In this tutorial, we'll begin by looking at the abstract base class called `Reader`. After studying the code, we'll look at a specific implementation of a `Reader` known as `CSVReader`, an object that is used to read generic CSV files and that is highly customizable.\n",
    "\n",
    "## Special note\n",
    "\n",
    "Version 1.1.0 introduced the Reader interface and two readers: `CSVReader` and `JSONReader`. In this version they only work for Localizations, FiducialTracks, and AverageFiducial datasetTypes. Finally, they cannot be specified in the GUI, but may be specified using the new `readers` parameter of `HDFDatastore.build()`. All of these limitations should be gone in future versions of B-Store. Readers for non-tabulated data, such as images, should follow as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `Reader` interface\n",
    "\n",
    "Let's begin by looking at the code for a `Reader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import B-Store's parsers module\n",
    "from bstore import readers\n",
    "\n",
    "# Used to retrieve the code\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Reader(metaclass=ABCMeta):\n",
      "    \"\"\"Reads the data for a given DatasetType from file.\n",
      "\n",
      "    \"\"\"\n",
      "    @abstractmethod\n",
      "    def __call__(self, filename, **kwargs):\n",
      "        \"\"\"Reads the data inside a file into a Python object.\n",
      "\n",
      "        Note that a return type function annotation must be specified in the\n",
      "        concrete methods to automatically match a Reader with a DatasetType.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : str or buffer object\n",
      "            The file containing the data to read.\n",
      "        **kwargs : dict\n",
      "            key-value arguments to pass to the auxillary functions used by the\n",
      "            file reading functions.\n",
      "\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def __repr__(self):\n",
      "        pass\n",
      "\n",
      "    @abstractproperty\n",
      "    def __signature__(self):\n",
      "        \"\"\"The custom Signature object for the class's __call__ method.\n",
      "\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n",
      "    @abstractmethod\n",
      "    def __str__(self):\n",
      "        \"\"\"User-friendly and short description of the Reader.\n",
      "\n",
      "        This will appear in GUI menus.\n",
      "\n",
      "        \"\"\"\n",
      "        pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(readers.Reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the code above, we can see that a Reader must have three methods and one property. The methods are:\n",
    "\n",
    "1. __call__ : This makes the object a callable, i.e. an instance may be used like a function.\n",
    "2. __repr__ : This is a Python builtin function that will return a that may be used to instantiate a Reader instance.\n",
    "3. __str__ : This is a more user-friendly method that returns a string describing what the Reader does.\n",
    "\n",
    "The property that must be defined is `__signature__`. The reason for this property is that we must define the call signature for the Reader object when it is called like a function. [The call signature](https://docs.python.org/3/library/inspect.html#inspect.Signature) represents the arguments and their default values that are passed to the Reader when it is called like a function inside the `readFromFile` method of a DatasetType. Specifying a call signature will enable us to modify the arguments through a GUI window with all the argument names and values. Without a signature, we cannot easily \"look inside\" the Reader to figure out what arguments it takes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The `CSVReader` object\n",
    "\n",
    "Let's now take a look at a concrete Reader, the `CSVReader`, which enables us to read generic .csv files in a highly customizable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class CSVReader(Reader):\n",
      "    \"\"\"Reads data from a generic comma separated values (CSV) file.\n",
      "\n",
      "    This reader utilizes the Pandas read_csv() function, which allows many\n",
      "    different parameters to be adjusted, such as the value separator. For an\n",
      "    explanation of the parameters, see the reference below.\n",
      "\n",
      "    The constructor for CSVReader creates the class's custom call signature\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "    http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self):\n",
      "        # Create the custom call signature for this Reader\n",
      "        # https://docs.python.org/3.5/library/inspect.html#inspect.Signature\n",
      "        f = pd.read_csv\n",
      "        sig = inspect.signature(f)\n",
      "        p1 = inspect.Parameter(\n",
      "            'filename', inspect.Parameter.POSITIONAL_ONLY)\n",
      "\n",
      "        newParams = [p1] + [param for name, param in sig.parameters.items()\n",
      "                            if name != 'filepath_or_buffer']\n",
      "\n",
      "        self._sig = sig.replace(parameters=newParams)\n",
      "\n",
      "    def __call__(self, filename, **kwargs) -> pd.DataFrame:\n",
      "        \"\"\"Calls the CSV reading machinery.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        filename : str, Path, or buffer object\n",
      "            The filename of the file containing the data.\n",
      "        **kwargs : dict\n",
      "            key-value arguments to pass to the csv reading machinery.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Pandas DataFrame\n",
      "\n",
      "        \"\"\"\n",
      "        # Inspect read_csv and pull out only its keyword arguments from\n",
      "        # **kwargs. This will prevent errors in passing unrecognized kwargs.\n",
      "        kwargs = {k: v for k, v in kwargs.items()\n",
      "                  if k in self.__signature__.parameters\n",
      "                  and k != 'filename'}\n",
      "\n",
      "        return pd.read_csv(filename, **kwargs)\n",
      "\n",
      "    def __repr__(self):\n",
      "        return 'CSVReader()'\n",
      "\n",
      "    @property\n",
      "    def __signature__(self):\n",
      "        return self._sig\n",
      "\n",
      "    def __str__(self):\n",
      "        return 'Generic CSV File Reader'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader = readers.CSVReader\n",
    "print(inspect.getsource(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_\\_init\\_\\_()\n",
    "\n",
    "We define the CSVReader with the line:\n",
    "\n",
    "```python\n",
    "\n",
    "class CSVReader(Reader):\n",
    "\n",
    "```\n",
    "\n",
    "The `(Reader)` in parantheses tells Python that the object subclasses the `Reader` abstract base class discussed above.\n",
    "\n",
    "Following the docstring, there is the `__init__` function which serves as the constructor for the object. (Note that defining an `__init__` method is not required.) This Reader actually uses the [Pandas read_csv function](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) to read .csv files into Python DataFrames. Thefore, we extract the function signature from `read_csv` in the line\n",
    "\n",
    "```python\n",
    "\n",
    "sig = inspect.signature(pd.read_csv)\n",
    "\n",
    "```\n",
    "\n",
    "Now, we have to slightly modify the signature for our Reader because `read_csv` accepts an argument called `filename_or_buffer` as its first argument. However, inside each datasetType's `readFromFile` method, we specify the filePath as the first positional argument. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    @staticmethod\n",
      "    def readFromFile(filePath, **kwargs):\n",
      "        \"\"\"Read a file on disk containing the DatasetType.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        filePath : Path\n",
      "            A pathlib object pointing towards the file to open.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Pandas DataFrame\n",
      "\n",
      "        \"\"\"\n",
      "        if ('reader' in kwargs) and (kwargs['reader']):\n",
      "            reader = kwargs['reader']\n",
      "            return reader(str(filePath), **kwargs)\n",
      "        else:\n",
      "            # Default read behavior\n",
      "            return pd.read_csv(str(filePath))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bstore.datasetTypes import Localizations as locs\n",
    "readFromFile = locs.Localizations.readFromFile\n",
    "print(inspect.getsource(readFromFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the GUI, filePath is not specified by the user but rather by B-Store's machinery for automatically detecting files. When a GUI window appears to allow someone to set the parameters of `CSVReader`, we therefore do not want them to be able to set the argument `filename_or_buffer`.\n",
    "\n",
    "We define a custom call signature inside `__init__()` with the lines:\n",
    "\n",
    "```python\n",
    "\n",
    "p1  = inspect.Parameter(\n",
    "    'filename', inspect.Parameter.POSITIONAL_ONLY)\n",
    "            \n",
    "newParams = [p1] + [param for name, param in sig.parameters.items()\n",
    "                          if name != 'filepath_or_buffer']\n",
    "                                    \n",
    "self._sig = sig.replace(parameters = newParams)\n",
    "\n",
    "```\n",
    "\n",
    "`p1` is a custom parameter that is set to be `POSITIONAL_ONLY`. Doing this ensures that we can easily separate it from the rest of the arguments of `read_csv`, which are of the kind `POSITIONAL_OR_KEYWORD`. We then add this new custom parameter onto the all the other parameters of `read_csv` **except** for `filepath_or_buffer` with the lines\n",
    "\n",
    "```python\n",
    "\n",
    "p1  = inspect.Parameter(\n",
    "    'filename', inspect.Parameter.POSITIONAL_ONLY)\n",
    "            \n",
    "newParams = [p1] + [param for name, param in sig.parameters.items()\n",
    "                          if name != 'filepath_or_buffer']\n",
    "\n",
    "```\n",
    "\n",
    "Finally, the Reader's `_sig` property is reset to this new Signature with the line `self._sig = sig.replace(parameters = newParams)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __signature__\n",
    "\n",
    "To return this newly-defined signature object when the `Signature` function is called on our class, we tell the CSVReader's signature property to return it:\n",
    "\n",
    "```python\n",
    "\n",
    "@property        \n",
    "def __signature__(self):\n",
    "    return self._sig\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_\\_call\\_\\_(self, filename, **kwargs)\n",
    "\n",
    "The \\_\\_call\\_\\_() method actually performs the act of reading the data from a file into a DataFrame. First, all keyword arguments that are not part of `read_csv` are removed from the \\*\\*kwargs dict. If they are not removed, `read_csv` will raise an error about an unrecognized argument. We also ensure that filename is not passed to `read_csv`, in case it was passed as a keyword.\n",
    "\n",
    "```python\n",
    "\n",
    "kwargs = {k: v for k, v in kwargs.items()\n",
    "               if k in self.__signature__.parameters\n",
    "               and k != 'filename'}\n",
    "\n",
    "```\n",
    "\n",
    "Next, we simply call `read_csv` with the `filename` argument and the new `kwargs` dict and return the DataFrame as a result:\n",
    "\n",
    "```python\n",
    "\n",
    "return pd.read_csv(filename, **kwargs)\n",
    "\n",
    "```\n",
    "\n",
    "By passing \\*\\*kwargs into read_csv, we can assign values to *any* of `read_csv`'s arguments. `read_csv` accepts a very large number of arguments to allow you to customize its behavior. This powerful customizability is therefore translated to B-Store. One last important thing to note is the part at the end of the first line of \\_\\_call\\_\\_()'s definition:\n",
    "\n",
    "```python\n",
    "\n",
    "def __call__(self, filename, **kwargs) -> pd.DataFrame:\n",
    "\n",
    "```\n",
    "\n",
    "`-> pd.DataFrame` tells Python what datatype the function returns. This is also required by Readers and is used to automatically detect what Readers are associated with what datasetTypes. For example, Localizations are represented internally as DataFrames. `-> pd.DataFrame` tells B-Store that we can associate this reader with any datasetType that has a DataFrame as its internal representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\_\\_repr\\_\\_() and \\_\\_str\\_\\_()\n",
    "\n",
    "These methods should be self-explantory for Python developers. The first returns a string used by developers to represent how the instance is created and the second is a user-friendly string that can be displayed in places like the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "For this example, you can use the test data in the [bstore_test_files](https://github.com/kmdouglass/bstore_test_files). Download the files from Git using the link and change the path below to point to *bstore_test_files/readers_test_files/csv/tab_delimited* on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bstore import parsers\n",
    "from bstore import readers\n",
    "from pathlib import Path\n",
    "\n",
    "filePath     = Path('../../bstore_test_files/readers_test_files/csv/tab_delimited/')\n",
    "filename     = filePath / Path('HeLaL_Control_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Parser and Reader                        \n",
    "parser = parsers.SimpleParser()\n",
    "reader = readers.CSVReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>frame</th>\n",
       "      <th>uncertainty</th>\n",
       "      <th>intensity</th>\n",
       "      <th>offset</th>\n",
       "      <th>loglikelihood</th>\n",
       "      <th>sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6770.0</td>\n",
       "      <td>59386</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>9.5138</td>\n",
       "      <td>4386.6</td>\n",
       "      <td>270.24</td>\n",
       "      <td>425.92</td>\n",
       "      <td>218.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7958.1</td>\n",
       "      <td>59762</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6.7329</td>\n",
       "      <td>8310.3</td>\n",
       "      <td>562.65</td>\n",
       "      <td>619.47</td>\n",
       "      <td>199.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7840.8</td>\n",
       "      <td>60819</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2.1987</td>\n",
       "      <td>15671.0</td>\n",
       "      <td>1261.10</td>\n",
       "      <td>1691.40</td>\n",
       "      <td>119.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8090.2</td>\n",
       "      <td>59801</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>7.6282</td>\n",
       "      <td>6952.3</td>\n",
       "      <td>642.53</td>\n",
       "      <td>506.19</td>\n",
       "      <td>206.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9010.3</td>\n",
       "      <td>59647</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6.5814</td>\n",
       "      <td>8408.1</td>\n",
       "      <td>684.29</td>\n",
       "      <td>821.24</td>\n",
       "      <td>197.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x      y  z  frame  uncertainty  intensity   offset  loglikelihood  \\\n",
       "0  6770.0  59386  0     50       9.5138     4386.6   270.24         425.92   \n",
       "1  7958.1  59762  0     50       6.7329     8310.3   562.65         619.47   \n",
       "2  7840.8  60819  0     50       2.1987    15671.0  1261.10        1691.40   \n",
       "3  8090.2  59801  0     50       7.6282     6952.3   642.53         506.19   \n",
       "4  9010.3  59647  0     50       6.5814     8408.1   684.29         821.24   \n",
       "\n",
       "    sigma  \n",
       "0  218.79  \n",
       "1  199.50  \n",
       "2  119.47  \n",
       "3  206.46  \n",
       "4  197.90  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reader keyword argument passes the CSVReader instance;\n",
    "# all other keyword arguments are passed to CSVReader's __call__ function.\n",
    "parser.parseFilename(filename, datasetType = 'Localizations', reader = reader, sep = '\\t')\n",
    "\n",
    "parser.dataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we parsed the file containing localization data using the `CSVReader`. After creating the reader, we passed it as a keyword argument to parser's `parseFilename` method:\n",
    "\n",
    "```python\n",
    "\n",
    "parser.parseFilename(filename, datasetType = 'Localizations', reader = reader, sep = '\\t')\n",
    "\n",
    "```\n",
    "\n",
    "The maining keyword argument, `sep`, was passed to `read_csv` inside the reader because all keyword arguments after `datasetType` are passed to the reader object. We can pass other keyword arguments to `read_csv`, such as `skiprows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6770.0</th>\n",
       "      <th>59386</th>\n",
       "      <th>0</th>\n",
       "      <th>50</th>\n",
       "      <th>9.5138</th>\n",
       "      <th>4386.6</th>\n",
       "      <th>270.24</th>\n",
       "      <th>425.92</th>\n",
       "      <th>218.79</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7958.1</td>\n",
       "      <td>59762</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6.7329</td>\n",
       "      <td>8310.3</td>\n",
       "      <td>562.65</td>\n",
       "      <td>619.47</td>\n",
       "      <td>199.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7840.8</td>\n",
       "      <td>60819</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2.1987</td>\n",
       "      <td>15671.0</td>\n",
       "      <td>1261.10</td>\n",
       "      <td>1691.40</td>\n",
       "      <td>119.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8090.2</td>\n",
       "      <td>59801</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>7.6282</td>\n",
       "      <td>6952.3</td>\n",
       "      <td>642.53</td>\n",
       "      <td>506.19</td>\n",
       "      <td>206.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9010.3</td>\n",
       "      <td>59647</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>6.5814</td>\n",
       "      <td>8408.1</td>\n",
       "      <td>684.29</td>\n",
       "      <td>821.24</td>\n",
       "      <td>197.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9163.2</td>\n",
       "      <td>60771</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>2.5165</td>\n",
       "      <td>13696.0</td>\n",
       "      <td>1161.70</td>\n",
       "      <td>1307.20</td>\n",
       "      <td>124.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   6770.0  59386  0  50  9.5138   4386.6   270.24   425.92  218.79\n",
       "0  7958.1  59762  0  50  6.7329   8310.3   562.65   619.47  199.50\n",
       "1  7840.8  60819  0  50  2.1987  15671.0  1261.10  1691.40  119.47\n",
       "2  8090.2  59801  0  50  7.6282   6952.3   642.53   506.19  206.46\n",
       "3  9010.3  59647  0  50  6.5814   8408.1   684.29   821.24  197.90\n",
       "4  9163.2  60771  0  50  2.5165  13696.0  1161.70  1307.20  124.29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parseFilename(filename, datasetType = 'Localizations', reader = reader, sep = '\\t', skiprows = 1)\n",
    "\n",
    "parser.dataset.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passing readers to `HDFDatastore.build()`\n",
    "\n",
    "The `HDFDatastore.build()` method, which is the main method used to create Datastores, now accepts a keyword argument known as `readers`. This argument should be a dict whose keys are the names of DatasetTypes and whose values are instances of a particular reader to use when reading data.\n",
    "\n",
    "For example, let's say we want to build a Datastore from a small experiment and specify what readers to use when reading different dataset types. (You may need to change testDataRoot to point to the right folder containing the bstore test files.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bstore.config as config\n",
    "from bstore import database\n",
    "\n",
    "testData = Path('../../bstore_test_files/parsers_test_files/SimpleParser/')\n",
    "dsName = 'test_datastore.h5'\n",
    "config.__Registered_DatasetTypes__ = [\n",
    "    'Localizations', 'LocMetadata', 'WidefieldImage']   \n",
    "\n",
    "parser = parsers.SimpleParser()\n",
    "filenameStrings = {\n",
    "    'Localizations'  : '.csv',\n",
    "    'LocMetadata'    : '.txt',\n",
    "    'WidefieldImage' : '.tif'}\n",
    "readersDict = {'Localizations': readers.CSVReader()}\n",
    "\n",
    "# Note sep and skiprows are keyword arguments of CSVReader; readTiffTags is\n",
    "# a keyword argument for the WidefieldImage readfromFile() method\n",
    "with database.HDFDatastore(dsName) as myDS:\n",
    "    res = myDS.build(parser, testData, filenameStrings,\n",
    "                     readers=readersDict, sep=',', skiprows=2,\n",
    "                     readTiffTags = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code sets up a HDFDatastore build by first specifying the location of the data, the name of the HDFDatastore, and registering the desired DatasetTypes.\n",
    "\n",
    "```python\n",
    "testData = Path('../../bstore_test_files/parsers_test_files/SimpleParser/')\n",
    "dsName = 'test_datastore.h5'\n",
    "config.__Registered_DatasetTypes__ = [\n",
    "    'Localizations', 'LocMetadata', 'WidefieldImage']  \n",
    "```\n",
    "\n",
    "Next, a parser is specified and the naming pattern for the different datasets is specified like usual:\n",
    "\n",
    "```python\n",
    "parser = parsers.SimpleParser()\n",
    "filenameStrings = {\n",
    "    'Localizations'  : '.csv',\n",
    "    'LocMetadata'    : '.txt',\n",
    "    'WidefieldImage' : '.tif'}\n",
    "```\n",
    "\n",
    "We specify that we want to use the CSVReader for reading `Localizations` Datasets from files the `readersDict`:\n",
    "\n",
    "```python\n",
    "readersDict = {'Localizations': readers.CSVReader()}\n",
    "```\n",
    "\n",
    "Finally, we build the Datastore inside the *with...as* context manager like usual. We can pass keyword arguments to the various readers by specifying them **after the readers argument**. In this case, we send `sep=','` and `skiprows=2` to `CSVReader` and `readTiffTags=False`, which is sent to the `readFromFile` function of WidefieldImages.\n",
    "\n",
    "```python\n",
    "with database.HDFDatastore(dsName) as myDS:\n",
    "    res = myDS.build(parser, testData, filenameStrings,\n",
    "                     readers=readersDict, sep=',', skiprows=2,\n",
    "                     readTiffTags = False)\n",
    "```\n",
    "\n",
    "Currently, readers may only be specified in this manner for Localizations, FiducialTracks, and AverageFiducial dataset types. All other specifications will be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- A Reader may be used to actually read the raw data from a file whose name is currently be parsed by a Parser.\n",
    "- Readers are defined by an abstract base class known as `Reader`.\n",
    "- To define a concrete Reader, we have to define three methods and one property. The methods are `__call__()`, `__repr__()`, and `__str__()`. The property is `__signature__`.\n",
    "- Most of the work of creating a Reader goes into defining its signature. The signature is used to automatically detect what arguments the Reader requires and is used primarily by the GUI.\n",
    "- Any function or code at all for reading a raw data file may used inside `__call__()`. For `CSVReader`, we chose to use Pandas `read_csv` function because it is highly customizable.\n",
    "- To associate Readers with specific datasetTypes, we should use function annotations to specify the return type of the Reader's `__call__()` method."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
